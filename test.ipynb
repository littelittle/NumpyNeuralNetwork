{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 12, 13, 13)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from mynn import op as nn\n",
    "\n",
    "batchsize = 16\n",
    "\n",
    "# test 1 # \n",
    "# input = np.random.randn(batchsize, 10)\n",
    "# l1 = nn.Linear(10, 20)\n",
    "# l1(input).shape\n",
    "# grad = np.random.randn(batchsize, 20)\n",
    "# l1.backward(grad).shape\n",
    "\n",
    "# test 2 #\n",
    "def test2(verbose=False):\n",
    "    iter_time = 10000\n",
    "    N = 16*iter_time\n",
    "    X_data = np.random.randn(N, 10)\n",
    "    W_gt = np.random.randn(10, 20)\n",
    "    b_gt = np.random.randn(20)\n",
    "    Y_data = X_data@W_gt + b_gt\n",
    "    l2 = nn.Linear(10, 20)\n",
    "    for i in range(iter_time):\n",
    "        X = X_data[i*16:(i+1)*16, :]\n",
    "        Y_gt = Y_data[i*16:(i+1)*16, :]\n",
    "        Y_pred = l2(X)\n",
    "        loss = np.linalg.norm(Y_gt-Y_pred)\n",
    "        if verbose:\n",
    "            print(loss)\n",
    "        grad = -(Y_gt-Y_pred)\n",
    "        l2.backward(grad)\n",
    "        for key in l2.grads.keys():\n",
    "            l2.params[key] -= 1*l2.grads[key]\n",
    "            if np.any(np.isnan(l2.params[key])):\n",
    "                print(l2.grads[key])\n",
    "                print(grad)\n",
    "                raise ValueError(\"Need to break!!!\") \n",
    "        # print([np.linalg.norm(l2.params[key]) for key in l2.grads.keys()])\n",
    "    print(f\"the residual norm is {np.linalg.norm(l2.W-W_gt), np.linalg.norm(l2.b-b_gt)}\")\n",
    "\n",
    "def test3(verbose=False):\n",
    "    iter_time = 200000\n",
    "    N = 16*iter_time\n",
    "    X_data = np.random.randn(N, 10)\n",
    "    W_gt = np.random.randn(10, 20)\n",
    "    b_gt = np.random.randn(20)\n",
    "    Y_data = X_data@W_gt + b_gt\n",
    "    l1 = nn.Linear(10, 10)\n",
    "    relu = nn.ReLU()\n",
    "    l2 = nn.Linear(10, 20)\n",
    "    for i in range(iter_time):\n",
    "        X = X_data[i*16:(i+1)*16, :]\n",
    "        Y_gt = Y_data[i*16:(i+1)*16, :]\n",
    "        Y_pred = l2(relu(l1(X)))\n",
    "        loss = np.linalg.norm(Y_gt-Y_pred)\n",
    "        if verbose:\n",
    "            print(loss)\n",
    "        grad = -(Y_gt-Y_pred)\n",
    "\n",
    "        # passing the grad to l2!\n",
    "        passing_grad = l2.backward(grad)\n",
    "        print(f\"norm of the grad is {np.linalg.norm(grad)}\")\n",
    "        for key in l2.grads.keys():\n",
    "            l2.params[key] -= 0.01*l2.grads[key]\n",
    "            if np.any(np.isnan(l2.params[key])):\n",
    "                print(l2.grads[key])\n",
    "                print(f\"grad is {grad}\")\n",
    "                raise ValueError(\"l2 Need to break!!!\") \n",
    "            \n",
    "        # passing the grad to relu!\n",
    "        passing_grad = relu.backward(passing_grad)\n",
    "        # no params to optimize for relu!\n",
    "\n",
    "        # passing the grad to l1!\n",
    "        l1.backward(passing_grad)\n",
    "        print(np.linalg.norm(passing_grad))\n",
    "        for key in l1.grads.keys():\n",
    "            l1.params[key] -= 0.01*l1.grads[key]\n",
    "            if np.any(np.isnan(l1.params[key])):\n",
    "                print(l1.grads[key])\n",
    "                print(grad)\n",
    "                raise ValueError(\"l1 Need to break!!!\")        \n",
    "\n",
    "def test4():\n",
    "    con1 = nn.Conv2D(in_channels=3, out_channels=6, kernel_size=4)\n",
    "    con2 = nn.Conv2D(in_channels=6, out_channels=12, kernel_size=5, stride=2)\n",
    "    X = np.random.rand(16, 3, 32, 32)\n",
    "    print(con2(con1(X)).shape)\n",
    "    grad = np.zeros((16, 12, 13, 13))\n",
    "    con2.backward(grad)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.randn(16, 3, 4, 4)\n",
    "b = np.random.randn(6, 3, 4, 4)\n",
    "# np.matmul(a.reshape(16, -1),b.reshape(6, -1).transpose(1, 0)).shape\n",
    "# np.mean((np.random.randn(10,20,30).transpose(-1,-2)), axis=0).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
